{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Dropout, Concatenate, BatchNormalization, Average, Convolution2D, MaxPooling2D, Activation, GlobalMaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, Embedding, LSTM, GRU, TimeDistributed, Bidirectional\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.preprocessing.sequence import TimeseriesGenerator, pad_sequences, skipgrams\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model, to_categorical\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dz07lib import create_or_check_path, detect_encoding, read_and_modify_vocab, reverse_dict\n",
    "import threading\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.__version__.startswith(\"1.\"):\n",
    "    val_acc_name = \"val_acc\"\n",
    "    acc_name = \"acc\"\n",
    "else:\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "    val_acc_name = \"val_accuracy\"\n",
    "    acc_name = \"accuracy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# total_text_filepath = \"data/total_max_frei.txt\"\n",
    "total_text_filepath = \"data/raw_eng/train.50k\"\n",
    "print(os.path.isfile(total_text_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(total_text_filepath, \"rt\") as file:\n",
    "    lines = file.read().split(\"\\n\")\n",
    "lines = [line for line in lines if len(line) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE_LIMIT = 10000\n",
    "SEQUENCE_LENGTH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size before: 50596\n",
      "Vocab size after: 10000\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(lines)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Vocab size before:\", vocab_size)\n",
    "if vocab_size > VOCAB_SIZE_LIMIT:\n",
    "    vocab_size = VOCAB_SIZE_LIMIT\n",
    "print(\"Vocab size after:\", vocab_size)\n",
    "\n",
    "tokenizer.num_words = vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(pad_sequences(tokenizer.texts_to_sequences(lines), maxlen=SEQUENCE_LENGTH+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = sequences[:,:-1], sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49998, 50)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=3458273)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = X.shape[1]\n",
    "seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bocharick/anaconda3_for_saman/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/bocharick/anaconda3_for_saman/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 60)            600000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 50, 200)           208800    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50, 200)           320800    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50, 200)           320800    \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 200)               320800    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10000)             2010000   \n",
      "=================================================================\n",
      "Total params: 3,821,400\n",
      "Trainable params: 3,821,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del model\n",
    "except:\n",
    "    pass\n",
    "K.clear_session()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 60, input_length=seq_length))\n",
    "model.add(LSTM(200, return_sequences=True, activation='relu', recurrent_activation='relu', dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(LSTM(200, return_sequences=True, activation='relu', recurrent_activation='relu', dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(LSTM(200, return_sequences=True, activation='relu', recurrent_activation='relu', dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(LSTM(200, activation='relu', recurrent_activation='relu', dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the tokenizer\n",
    "pickle.dump(tokenizer, open('tokenizer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint('lm_for_tokenizer.hdf5',\n",
    "                            monitor=val_acc_name,\n",
    "                            save_best_only=True,\n",
    "                            period=1,\n",
    "                            verbose=1)\n",
    "early_stopping_callback = EarlyStopping(monitor=val_acc_name, \n",
    "                                        min_delta=1e-9, \n",
    "                                        patience=50, \n",
    "                                        verbose=1, \n",
    "                                        mode='auto', \n",
    "                                        baseline=None, \n",
    "                                        restore_best_weights=True)\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor=val_acc_name,\n",
    "                                           patience=10,\n",
    "                                           verbose=1,\n",
    "                                           factor=0.75,\n",
    "                                           min_lr=0.00000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 39998 samples, validate on 10000 samples\n",
      "Epoch 1/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 9.1196 - acc: 0.0336\n",
      "Epoch 00001: val_acc improved from -inf to 0.03480, saving model to lm_for_tokenizer.hdf5\n",
      "39998/39998 [==============================] - 48s 1ms/sample - loss: 9.1195 - acc: 0.0336 - val_loss: 9.0342 - val_acc: 0.0348\n",
      "Epoch 2/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 8.9482 - acc: 0.0343\n",
      "Epoch 00002: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 8.9481 - acc: 0.0343 - val_loss: 8.9014 - val_acc: 0.0348\n",
      "Epoch 3/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 8.8108 - acc: 0.0343\n",
      "Epoch 00003: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 8.8108 - acc: 0.0343 - val_loss: 8.7870 - val_acc: 0.0348\n",
      "Epoch 4/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 8.6908 - acc: 0.0343\n",
      "Epoch 00004: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 8.6908 - acc: 0.0343 - val_loss: 8.6866 - val_acc: 0.0348\n",
      "Epoch 5/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 8.5842 - acc: 0.0343\n",
      "Epoch 00005: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 8.5841 - acc: 0.0343 - val_loss: 8.5971 - val_acc: 0.0348\n",
      "Epoch 6/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 8.4883 - acc: 0.0343\n",
      "Epoch 00006: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 8.4882 - acc: 0.0343 - val_loss: 8.5166 - val_acc: 0.0348\n",
      "Epoch 7/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 8.4015 - acc: 0.0342\n",
      "Epoch 00007: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 8.4013 - acc: 0.0343 - val_loss: 8.4439 - val_acc: 0.0348\n",
      "Epoch 8/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 8.3225 - acc: 0.0342\n",
      "Epoch 00008: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 8.3223 - acc: 0.0343 - val_loss: 8.3781 - val_acc: 0.0348\n",
      "Epoch 9/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 8.2505 - acc: 0.0342\n",
      "Epoch 00009: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 8.2505 - acc: 0.0343 - val_loss: 8.3185 - val_acc: 0.0348\n",
      "Epoch 10/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 8.1852 - acc: 0.0343\n",
      "Epoch 00010: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 8.1851 - acc: 0.0343 - val_loss: 8.2648 - val_acc: 0.0348\n",
      "Epoch 11/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 8.1260 - acc: 0.0343\n",
      "Epoch 00011: val_acc did not improve from 0.03480\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0007500000356230885.\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 8.1258 - acc: 0.0343 - val_loss: 8.2167 - val_acc: 0.0348\n",
      "Epoch 12/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 8.0782 - acc: 0.0342\n",
      "Epoch 00012: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 8.0779 - acc: 0.0343 - val_loss: 8.1842 - val_acc: 0.0348\n",
      "Epoch 13/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 8.0405 - acc: 0.0343\n",
      "Epoch 00013: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 8.0406 - acc: 0.0343 - val_loss: 8.1545 - val_acc: 0.0348\n",
      "Epoch 14/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 8.0061 - acc: 0.0343\n",
      "Epoch 00014: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 8.0063 - acc: 0.0343 - val_loss: 8.1277 - val_acc: 0.0348\n",
      "Epoch 15/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.9751 - acc: 0.0343\n",
      "Epoch 00015: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.9749 - acc: 0.0343 - val_loss: 8.1039 - val_acc: 0.0348\n",
      "Epoch 16/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.9465 - acc: 0.0343\n",
      "Epoch 00016: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.9464 - acc: 0.0343 - val_loss: 8.0828 - val_acc: 0.0348\n",
      "Epoch 17/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.9205 - acc: 0.0342\n",
      "Epoch 00017: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.9205 - acc: 0.0343 - val_loss: 8.0644 - val_acc: 0.0348\n",
      "Epoch 18/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.8977 - acc: 0.0343\n",
      "Epoch 00018: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.8974 - acc: 0.0343 - val_loss: 8.0486 - val_acc: 0.0348\n",
      "Epoch 19/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.8764 - acc: 0.0343\n",
      "Epoch 00019: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.8768 - acc: 0.0343 - val_loss: 8.0353 - val_acc: 0.0348\n",
      "Epoch 20/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.8593 - acc: 0.0342\n",
      "Epoch 00020: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.8586 - acc: 0.0343 - val_loss: 8.0243 - val_acc: 0.0348\n",
      "Epoch 21/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.8426 - acc: 0.0343\n",
      "Epoch 00021: val_acc did not improve from 0.03480\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0005625000048894435.\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.8427 - acc: 0.0343 - val_loss: 8.0154 - val_acc: 0.0348\n",
      "Epoch 22/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.8298 - acc: 0.0343\n",
      "Epoch 00022: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.8299 - acc: 0.0343 - val_loss: 8.0101 - val_acc: 0.0348\n",
      "Epoch 23/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.8202 - acc: 0.0342\n",
      "Epoch 00023: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.8205 - acc: 0.0343 - val_loss: 8.0058 - val_acc: 0.0348\n",
      "Epoch 24/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.8119 - acc: 0.0343\n",
      "Epoch 00024: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.8120 - acc: 0.0343 - val_loss: 8.0024 - val_acc: 0.0348\n",
      "Epoch 25/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.8042 - acc: 0.0343\n",
      "Epoch 00025: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.8044 - acc: 0.0343 - val_loss: 8.0000 - val_acc: 0.0348\n",
      "Epoch 26/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7975 - acc: 0.0343\n",
      "Epoch 00026: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7975 - acc: 0.0343 - val_loss: 7.9983 - val_acc: 0.0348\n",
      "Epoch 27/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7913 - acc: 0.0343\n",
      "Epoch 00027: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7913 - acc: 0.0343 - val_loss: 7.9973 - val_acc: 0.0348\n",
      "Epoch 28/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7852 - acc: 0.0343\n",
      "Epoch 00028: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7856 - acc: 0.0343 - val_loss: 7.9970 - val_acc: 0.0348\n",
      "Epoch 29/9999999999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7806 - acc: 0.0343\n",
      "Epoch 00029: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7805 - acc: 0.0343 - val_loss: 7.9971 - val_acc: 0.0348\n",
      "Epoch 30/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7762 - acc: 0.0343\n",
      "Epoch 00030: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7758 - acc: 0.0343 - val_loss: 7.9977 - val_acc: 0.0348\n",
      "Epoch 31/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7714 - acc: 0.0343\n",
      "Epoch 00031: val_acc did not improve from 0.03480\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0004218749818392098.\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7715 - acc: 0.0343 - val_loss: 7.9987 - val_acc: 0.0348\n",
      "Epoch 32/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7677 - acc: 0.0343\n",
      "Epoch 00032: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7677 - acc: 0.0343 - val_loss: 7.9998 - val_acc: 0.0348\n",
      "Epoch 33/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7652 - acc: 0.0342\n",
      "Epoch 00033: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7650 - acc: 0.0343 - val_loss: 8.0010 - val_acc: 0.0348\n",
      "Epoch 34/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7629 - acc: 0.0343\n",
      "Epoch 00034: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7624 - acc: 0.0343 - val_loss: 8.0026 - val_acc: 0.0348\n",
      "Epoch 35/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7601 - acc: 0.0342\n",
      "Epoch 00035: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7599 - acc: 0.0343 - val_loss: 8.0043 - val_acc: 0.0348\n",
      "Epoch 36/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7574 - acc: 0.0343\n",
      "Epoch 00036: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7576 - acc: 0.0343 - val_loss: 8.0062 - val_acc: 0.0348\n",
      "Epoch 37/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7551 - acc: 0.0343\n",
      "Epoch 00037: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7554 - acc: 0.0343 - val_loss: 8.0083 - val_acc: 0.0348\n",
      "Epoch 38/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7533 - acc: 0.0342\n",
      "Epoch 00038: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7534 - acc: 0.0343 - val_loss: 8.0106 - val_acc: 0.0348\n",
      "Epoch 39/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7515 - acc: 0.0343\n",
      "Epoch 00039: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7515 - acc: 0.0343 - val_loss: 8.0129 - val_acc: 0.0348\n",
      "Epoch 40/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7498 - acc: 0.0343\n",
      "Epoch 00040: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7497 - acc: 0.0343 - val_loss: 8.0154 - val_acc: 0.0348\n",
      "Epoch 41/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7483 - acc: 0.0343\n",
      "Epoch 00041: val_acc did not improve from 0.03480\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.00031640623637940735.\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7480 - acc: 0.0343 - val_loss: 8.0180 - val_acc: 0.0348\n",
      "Epoch 42/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7460 - acc: 0.0343\n",
      "Epoch 00042: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7462 - acc: 0.0343 - val_loss: 8.0201 - val_acc: 0.0348\n",
      "Epoch 43/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7454 - acc: 0.0342\n",
      "Epoch 00043: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7451 - acc: 0.0343 - val_loss: 8.0222 - val_acc: 0.0348\n",
      "Epoch 44/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7444 - acc: 0.0342\n",
      "Epoch 00044: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7440 - acc: 0.0343 - val_loss: 8.0244 - val_acc: 0.0348\n",
      "Epoch 45/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7426 - acc: 0.0343\n",
      "Epoch 00045: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7429 - acc: 0.0343 - val_loss: 8.0267 - val_acc: 0.0348\n",
      "Epoch 46/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7420 - acc: 0.0342\n",
      "Epoch 00046: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7419 - acc: 0.0343 - val_loss: 8.0291 - val_acc: 0.0348\n",
      "Epoch 47/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7404 - acc: 0.0343\n",
      "Epoch 00047: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7409 - acc: 0.0343 - val_loss: 8.0315 - val_acc: 0.0348\n",
      "Epoch 48/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7391 - acc: 0.0343\n",
      "Epoch 00048: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7399 - acc: 0.0343 - val_loss: 8.0339 - val_acc: 0.0348\n",
      "Epoch 49/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7393 - acc: 0.0342\n",
      "Epoch 00049: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7390 - acc: 0.0343 - val_loss: 8.0364 - val_acc: 0.0348\n",
      "Epoch 50/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7385 - acc: 0.0343\n",
      "Epoch 00050: val_acc did not improve from 0.03480\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7382 - acc: 0.0343 - val_loss: 8.0389 - val_acc: 0.0348\n",
      "Epoch 51/9999999999\n",
      "39936/39998 [============================>.] - ETA: 0s - loss: 7.7372 - acc: 0.0343\n",
      "Epoch 00051: val_acc did not improve from 0.03480\n",
      "\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00023730468819849193.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "39998/39998 [==============================] - 46s 1ms/sample - loss: 7.7373 - acc: 0.0343 - val_loss: 8.0415 - val_acc: 0.0348\n",
      "Epoch 00051: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5351c0cd68>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "model.fit(X_train, y_train, \n",
    "          batch_size=128, \n",
    "          epochs=9999999999, \n",
    "          callbacks=[checkpoint, learning_rate_reduction, early_stopping_callback],\n",
    "         validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.p. a man who committed murder at age eleven pleaded guilty to drug possession monday less than two years after he was released from juvenile detention for the killing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# select a seed text\n",
    "seed_text = \"\"\n",
    "while len(seed_text) < 150:\n",
    "    random.seed(time.time())\n",
    "    seed_text = lines[random.randint(0,len(lines))]\n",
    "print(seed_text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 50)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = tokenizer.texts_to_sequences([seed_text])\n",
    "encoded = pad_sequences(encoded, maxlen=SEQUENCE_LENGTH)\n",
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "1/1 [==============================] - 0s 257ms/sample\n"
     ]
    }
   ],
   "source": [
    "# predict probabilities for each word\n",
    "yhat = model.predict_classes(encoded, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_word = ''\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    if index == yhat:\n",
    "        out_word = word\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a sequence from a language model\n",
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "    result = list()\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # predict probabilities for each word\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += ' ' + out_word\n",
    "#         print(in_text)\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed string:\n",
      " a.p. a man who committed murder at age eleven pleaded guilty to drug possession monday less than two years after he was released from juvenile detention for the killing\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Seed string:\\n\", seed_text + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:\n",
      "said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said said\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated text:\")\n",
    "generated_text = generate_seq(model, tokenizer, seq_length, seed_text, 100)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
